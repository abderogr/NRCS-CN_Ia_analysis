{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the library \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This part is for calculating the CN values and ranking them based on precipitation events\n",
    "# Function using the NRCS-CN method\n",
    "def quickflow_scs(CN, P, a):\n",
    "    \"\"\"\n",
    "    Calculate runoff using the NRCS method.\n",
    "    Parameters:\n",
    "    - S: Soil retention potential\n",
    "    - P: Total precipitation\n",
    "    - a: Initial abstraction ratio \n",
    "    Returns:\n",
    "    - Q: Quickflow (runoff)\n",
    "    \"\"\"\n",
    "\n",
    "    S = (25400 / CN) - 254\n",
    "    Ia = a * S\n",
    "    return np.where(P <= Ia, 0, ((P - Ia) ** 2) / (P - Ia + S))\n",
    "\n",
    "def calculate_values_and_curves(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['original_index'] = df.index\n",
    "    \n",
    "    # Sort values by total precipitation and quickflow independently\n",
    "    df = df.sort_values(by=['total_precipitation_sum', 'Quickflow_eckhardt'], ascending=[False, False])\n",
    "    \n",
    "    print(\"Após ordenar os valores:\", df.shape)\n",
    "    print(df[['total_precipitation_sum', 'Quickflow_eckhardt']].head())\n",
    "\n",
    "    \n",
    "    ### Calculate CN values for 0.2 and 0.005 scenarios\n",
    "    # Calculate S (retention) and CN for 0.2 scenario\n",
    "    df['S_02'] = df.apply(lambda row: 5*((row['total_precipitation_sum'] + 2*row['Quickflow_eckhardt']) - \n",
    "                            math.sqrt(4*math.pow(row['Quickflow_eckhardt'],2) + \n",
    "                           5*row['total_precipitation_sum']*row['Quickflow_eckhardt'])), axis=1)\n",
    "    df['CN_02'] = df.apply(lambda row: 25400/(254+row['S_02']), axis=1)\n",
    "    \n",
    "    # Calculate S and CN for 0.005\n",
    "    df['S_005'] = df.apply(lambda row: 10*((2*row['total_precipitation_sum'] + 19*row['Quickflow_eckhardt']) - \n",
    "                             math.sqrt(361*math.pow(row['Quickflow_eckhardt'],2) + \n",
    "                             80*row['total_precipitation_sum']*row['Quickflow_eckhardt'])), axis=1)\n",
    "    df['CN_005'] = df.apply(lambda row: 25400/(254+row['S_005']), axis=1)\n",
    "    \n",
    "    # Calculate CN0\n",
    "    df['CN0'] = 100/(1 + df[\"total_precipitation_sum\"]/2)\n",
    " \n",
    "    return df\n",
    "\n",
    "\n",
    "folder_path = r'Times_series\\ASY\\Group1' # Data series location\n",
    "results_path = r''  # Output directory for results\n",
    "\n",
    "\n",
    "def process_files(folder_path):\n",
    "    csv_files = [os.path.join(root, name) for root, dirs, files in os.walk(folder_path) for name in files if name.endswith(\".csv\")]\n",
    "\n",
    "    for file in csv_files:\n",
    "        df = calculate_values_and_curves(file)  \n",
    "        \n",
    "        # Salva o DataFrame modificado\n",
    "        output_file_path = os.path.join(results_path, os.path.basename(file))\n",
    "        df.to_csv(output_file_path, index=False)\n",
    "\n",
    "process_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Part two to adjust the standard behavior and find the CN value\n",
    "# Error metrics for model evaluation\n",
    "def error_metrics(observed, estimated):\n",
    "    residuals = observed - estimated\n",
    "    mse = np.mean(residuals**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(residuals))\n",
    "    return mse, rmse, mae\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    correlation_matrix = np.corrcoef(y_true, y_pred)\n",
    "    correlation_xy = correlation_matrix[0, 1]\n",
    "    return correlation_xy ** 2\n",
    "\n",
    "def PBIAS(observed, simulated):\n",
    "    return (np.sum(observed - simulated) / np.sum(observed)) * 100\n",
    "\n",
    "def NSE(observed, simulated):\n",
    "    return 1 - (np.sum((observed - simulated) ** 2) / np.sum((observed - np.mean(observed)) ** 2))\n",
    "\n",
    "def KGE(observed, simulated):\n",
    "    r = np.corrcoef(observed, simulated)[0, 1]\n",
    "    alpha = np.std(simulated) / np.std(observed)\n",
    "    beta = np.mean(simulated) / np.mean(observed)\n",
    "    return 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\n",
    "\n",
    "def RSE(observed, simulated):\n",
    "    observed = np.array(observed)\n",
    "    simulated = np.array(simulated)\n",
    "    n = len(observed)\n",
    "    \n",
    "    if n <= 2:\n",
    "        return np.nan  # Return NaN if we can't compute RSE\n",
    "    \n",
    "    # Mean of the observed data\n",
    "    y_obs_mean = np.mean(observed)\n",
    "    sum_squared_diff = np.sum((observed - simulated) ** 2)\n",
    "    sum_squared_total = np.sum((observed - y_obs_mean) ** 2)\n",
    "    \n",
    "    # If sum_squared_total is 0, RSE cannot be calculated as it would involve division by zero\n",
    "    if sum_squared_total == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return np.sqrt((n * sum_squared_diff) / ((n - 2) * sum_squared_total))\n",
    "\n",
    "# Standard curve adjustment\n",
    "def f_standard(P, k1, CNinf_stand):\n",
    "     calculated_values = CNinf_stand + (100 - CNinf_stand) * np.exp(-k1 * P)\n",
    "     print(\"Valores calculados antes do clipping:\", calculated_values)\n",
    "     clipped_values = np.clip(calculated_values, 0, 100) # Ensure CN values are within logical bounds\n",
    "     print(\"Valores após clipping:\", clipped_values)\n",
    "     return clipped_values\n",
    "\n",
    "# Curve fitting and metrics calculation\n",
    "\n",
    "def fit_curve_and_calculate_metrics(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Extract precipitation (P), CN_02, and CN_005 values\n",
    "    P = df[\"total_precipitation_sum\"].values\n",
    "    CN_02 = df[\"CN_02\"].values\n",
    "    CN_005 = df[\"CN_005\"].values\n",
    "\n",
    "    # Apply curve fitting for CN_02\n",
    "    params_02, _ = curve_fit(f_standard, P, CN_02,p0=[0.1, 50], bounds=([-10, 0], [10, 100]))\n",
    "    k1_fit_02, CNinf_stand_fit_02 = params_02\n",
    "    CN_stand_estimated_02 = f_standard(P, k1_fit_02, CNinf_stand_fit_02)\n",
    "\n",
    "    # Apply curve fitting for CN_005\n",
    "    params_005, _ = curve_fit(f_standard, P, CN_005, p0=[0.1, 50], bounds=([-10, 0], [10, 100]))\n",
    "    k1_fit_005, CNinf_stand_fit_005 = params_005\n",
    "    CN_stand_estimated_005 = f_standard(P, k1_fit_005, CNinf_stand_fit_005)\n",
    "\n",
    "    # Calculate metrics for CN_02\n",
    "    mse_02, rmse_02, mae_02 = error_metrics(CN_02, CN_stand_estimated_02)\n",
    "    pbias_02 = PBIAS(CN_02, CN_stand_estimated_02)\n",
    "    nse_02 = NSE(CN_02, CN_stand_estimated_02)\n",
    "    kge_02 = KGE(CN_02, CN_stand_estimated_02)\n",
    "    r2_02 = r2(CN_02, CN_stand_estimated_02)\n",
    "    rse_02 = RSE(CN_02, CN_stand_estimated_02)\n",
    "\n",
    "    # Calculate metrics for CN_005\n",
    "    mse_005, rmse_005, mae_005 = error_metrics(CN_005, CN_stand_estimated_005)\n",
    "    pbias_005 = PBIAS(CN_005, CN_stand_estimated_005)\n",
    "    nse_005 = NSE(CN_005, CN_stand_estimated_005)\n",
    "    kge_005 = KGE(CN_005, CN_stand_estimated_005)\n",
    "    r2_005 = r2(CN_005, CN_stand_estimated_005)\n",
    "    rse_005 = RSE(CN_005, CN_stand_estimated_005)\n",
    "    \n",
    "    # Compile results\n",
    "    results = {\n",
    "        'CN_02': {'k1': k1_fit_02, 'CNinf_stand': CNinf_stand_fit_02, 'mse': mse_02, 'rmse': rmse_02, 'mae': mae_02, 'pbias': pbias_02, 'nse': nse_02, 'kge': kge_02, 'r2': r2_02,'rse': rse_02},\n",
    "        'CN_005': {'k1': k1_fit_005, 'CNinf_stand': CNinf_stand_fit_005, 'mse': mse_005, 'rmse': rmse_005, 'mae': mae_005, 'pbias': pbias_005, 'nse': nse_005, 'kge': kge_005, 'r2': r2_005,'rse': rse_005}\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# Main function to process files within a folder and compile results into a CSV file\n",
    "def process_files(folder_path, results_file_path):\n",
    "    csv_files = [os.path.join(root, name) for root, dirs, files in os.walk(folder_path) for name in files if name.endswith(\".csv\")]\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    for file_path in csv_files:\n",
    "        # Calcula os resultados de ajuste de curva\n",
    "        metrics = fit_curve_and_calculate_metrics(file_path)\n",
    "\n",
    "        # Prepara um dicionário com os resultados para cada métrica\n",
    "        results_dict = {}\n",
    "        for metric in metrics:\n",
    "            for key, value in metrics[metric].items():\n",
    "                results_dict[f\"{metric}_{key}\"] = value\n",
    "\n",
    "        results_dict['file'] = os.path.basename(file_path)\n",
    "        all_results.append(results_dict)\n",
    "        \n",
    "    # Compile all results into a DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    results_df.to_csv(results_file_path, index=False)\n",
    "\n",
    "folder_path = r\"\" # # Specify the folder containing the series\n",
    "results_file_path = r\"\\CNs_stand.csv\"\n",
    "process_files(folder_path, results_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part three calculating the runoff from CN\n",
    "\n",
    "cn_file_path = r\"\\Times_series\\ASY\\Group1\\CNs_stand.csv\"\n",
    "series_folder_path = r\"\\Times_series\\ASY\\Group1\"\n",
    "\n",
    "# Function to compute error metrics\n",
    "def error_metrics(observed, estimated):\n",
    "    residuals = observed - estimated\n",
    "    mse = np.mean(residuals**2)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = np.mean(np.abs(residuals))\n",
    "    return mse, rmse, mae\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    correlation_matrix = np.corrcoef(y_true, y_pred)\n",
    "    correlation_xy = correlation_matrix[0, 1]\n",
    "    return correlation_xy ** 2\n",
    "\n",
    "def PBIAS(observed, simulated):\n",
    "    return (np.sum(observed - simulated) / np.sum(observed)) * 100\n",
    "\n",
    "def NSE(observed, simulated):\n",
    "    return 1 - (np.sum((observed - simulated) ** 2) / np.sum((observed - np.mean(observed)) ** 2))\n",
    "\n",
    "def KGE(observed, simulated):\n",
    "    r = np.corrcoef(observed, simulated)[0, 1]\n",
    "    alpha = np.std(simulated) / np.std(observed)\n",
    "    beta = np.mean(simulated) / np.mean(observed)\n",
    "    return 1 - np.sqrt((r - 1) ** 2 + (alpha - 1) ** 2 + (beta - 1) ** 2)\n",
    "\n",
    "def RSE(observed, simulated):\n",
    "    observed = np.array(observed)\n",
    "    simulated = np.array(simulated)\n",
    "    n = len(observed)\n",
    "    \n",
    "    if n <= 2:\n",
    "        return np.nan  # Return NaN if we can't compute RSE\n",
    "    \n",
    "    # Mean of the observed data\n",
    "    y_obs_mean = np.mean(observed)\n",
    "    sum_squared_diff = np.sum((observed - simulated) ** 2)\n",
    "    sum_squared_total = np.sum((observed - y_obs_mean) ** 2)\n",
    "    \n",
    "    # If sum_squared_total is 0, RSE cannot be calculated as it would involve division by zero\n",
    "    if sum_squared_total == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    return np.sqrt((n * sum_squared_diff) / ((n - 2) * sum_squared_total))\n",
    "\n",
    "# Quickflow calculation using the NRCS method\n",
    "def quickflow_scs(CN, P, a):\n",
    "    \"\"\"\n",
    "    Calculate quickflow (runoff) using the NRCS method.\n",
    "\n",
    "    Parameters:\n",
    "    - S: Soil retention potential\n",
    "    - P: Total precipitation\n",
    "    - a: Initial abstraction ratio \n",
    "    Returns:\n",
    "    - Q: Quickflow (runoff)\n",
    "    \"\"\"\n",
    "\n",
    "    S = (25400 / CN) - 254\n",
    "    Ia = a * S\n",
    "    return np.where(P <= Ia, 0, ((P - Ia) ** 2) / (P - Ia + S))\n",
    "\n",
    "# Initialize a list to store all metric dictionaries\n",
    "all_metrics = []\n",
    "df_cn = pd.read_csv(cn_file_path)\n",
    "\n",
    "# Map file names to their full paths\n",
    "file_locations = {}\n",
    "for root, dirs, files in os.walk(series_folder_path):\n",
    "    for file in files:\n",
    "        file_locations[file] = os.path.join(root, file)\n",
    "        \n",
    "# Iterate over each row in the CN dataframe\n",
    "      \n",
    "for index, row in df_cn.iterrows():\n",
    "    file_name = row['file'] + '.csv'\n",
    "    cn02 = row['CN_02_CNinf_stand']\n",
    "    cn005 = row['CN_005_CNinf_stand']\n",
    "\n",
    "    # Locate and read the corresponding series file\n",
    "    series_file_path = os.path.join(series_folder_path, file_name)\n",
    "    \n",
    "    if file_name in file_locations:\n",
    "        series_file_path = file_locations[file_name]\n",
    "        df_series = pd.read_csv(series_file_path)\n",
    "        P = df_series[\"total_precipitation_sum\"].values\n",
    "        Q_observed = df_series[\"Quickflow_eckhardt\"].values\n",
    "\n",
    "        # Calculate estimated quickflow for two scenarios\n",
    "        Q_estimated_02 = quickflow_scs(cn02, P, 0.2)\n",
    "        Q_estimated_005 = quickflow_scs(cn005, P, 0.05)\n",
    "        \n",
    "        # Store metrics for lambda 0.2 scenario\n",
    "\n",
    "        metrics_dict = {\n",
    "            'file': file_name,\n",
    "            'mse_02': error_metrics(Q_observed, Q_estimated_02)[0],\n",
    "            'rmse_02': error_metrics(Q_observed, Q_estimated_02)[1],\n",
    "            'mae_02': error_metrics(Q_observed, Q_estimated_02)[2],\n",
    "            'r2_02': r2(Q_observed, Q_estimated_02),\n",
    "            'pbias_02': PBIAS(Q_observed, Q_estimated_02),\n",
    "            'nse_02': NSE(Q_observed, Q_estimated_02),\n",
    "            'kge_02': KGE(Q_observed, Q_estimated_02),\n",
    "            'rse_02': KGE(Q_observed, Q_estimated_02)\n",
    "        }\n",
    "    \n",
    "        # Store metrics for lambda 0.05 scenario\n",
    "        metrics_dict.update({\n",
    "            'mse_005': error_metrics(Q_observed, Q_estimated_005)[0],\n",
    "            'rmse_005': error_metrics(Q_observed, Q_estimated_005)[1],\n",
    "            'mae_005': error_metrics(Q_observed, Q_estimated_005)[2],\n",
    "            'r2_005': r2(Q_observed, Q_estimated_005),\n",
    "            'pbias_005': PBIAS(Q_observed, Q_estimated_005),\n",
    "            'nse_005': NSE(Q_observed, Q_estimated_005),\n",
    "            'rse_005': KGE(Q_observed, Q_estimated_005),\n",
    "        })\n",
    "\n",
    "        all_metrics.append(metrics_dict)\n",
    "\n",
    "        # Add estimated quickflow values to the original spreadsheet\n",
    "        df_series['Q_estimated_02'] = Q_estimated_02\n",
    "        df_series['Q_estimated_005'] = Q_estimated_005\n",
    "        df_series.to_csv(os.path.join(series_folder_path, file_name), index=False)\n",
    "    else:\n",
    "     print(f\"Arquivo não encontrado: {series_file_path}\") \n",
    "     \n",
    "# Save all collected metrics to a CSV file\n",
    "metrics_df = pd.DataFrame(all_metrics)\n",
    "metrics_df.to_csv(os.path.join(series_folder_path, 'results_ASY_G1.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
